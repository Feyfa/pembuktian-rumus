{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5621273",
   "metadata": {},
   "source": [
    "\n",
    "# Tutorial: Head-to-Head: Comparing Multiple Models with Cross-Validation\n",
    "\n",
    "Selamat datang di subchapter 4.2! Setelah kita menetapkan skor baseline yang harus dikalahkan, sekarang saatnya untuk mengadu beberapa model canggih dalam sebuah \"turnamen\" yang adil.\n",
    "\n",
    "**Tujuan:** Kita akan belajar cara menulis skrip yang efisien untuk melatih dan mengevaluasi beberapa model yang berbeda secara sistematis. Kita akan menggunakan **Cross-Validation** untuk memastikan perbandingan kita adil dan andal, bukan hanya berdasarkan \"keberuntungan\" dari satu kali `train_test_split`.\n",
    "\n",
    "Di akhir notebook ini, kita akan memiliki daftar peringkat yang jelas tentang model mana yang paling menjanjikan untuk masalah kita.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6814dd1",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### 1. Tujuan Pembelajaran\n",
    "\n",
    "Di akhir notebook ini, Anda akan dapat:\n",
    "\n",
    "* Menyiapkan daftar model kandidat untuk dievaluasi.\n",
    "* Membuat *loop* untuk melatih dan mengevaluasi setiap model menggunakan `cross_val_score`.\n",
    "* Menyimpan dan membandingkan hasil performa dari setiap model secara terstruktur.\n",
    "* Menentukan model-model teratas yang layak untuk dianalisis lebih lanjut.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f5b808",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### 2. Setup: Data dan Library\n",
    "\n",
    "Kita akan memuat semua \"kontestan\" kita di awal. Ini termasuk model linear sederhana, model regularisasi, dan model ensemble yang kuat.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ad6edb6",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor, GradientBoostingRegressor\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Muat data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m housing = \u001b[43mfetch_california_housing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m X, y = housing.data, housing.target\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# PENTING: Untuk cross-validation, kita bisa menggunakan seluruh dataset (X, y)\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# karena cross_val_score akan menangani pembagiannya secara internal.\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Namun, untuk praktik terbaik, kita tetap akan memisahkan test set untuk evaluasi akhir di subchapter selanjutnya.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/sklearn/datasets/_california_housing.py:175\u001b[39m, in \u001b[36mfetch_california_housing\u001b[39m\u001b[34m(data_home, download_if_missing, return_X_y, as_frame, n_retries, delay)\u001b[39m\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mData not found and `download_if_missing` is False\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    171\u001b[39m logger.info(\n\u001b[32m    172\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mDownloading Cal. housing from \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(ARCHIVE.url, data_home)\n\u001b[32m    173\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m archive_path = \u001b[43m_fetch_remote\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m    \u001b[49m\u001b[43mARCHIVE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_home\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tarfile.open(mode=\u001b[33m\"\u001b[39m\u001b[33mr:gz\u001b[39m\u001b[33m\"\u001b[39m, name=archive_path) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    183\u001b[39m     cal_housing = np.loadtxt(\n\u001b[32m    184\u001b[39m         f.extractfile(\u001b[33m\"\u001b[39m\u001b[33mCaliforniaHousing/cal_housing.data\u001b[39m\u001b[33m\"\u001b[39m), delimiter=\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    185\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/sklearn/datasets/_base.py:1513\u001b[39m, in \u001b[36m_fetch_remote\u001b[39m\u001b[34m(remote, dirname, n_retries, delay)\u001b[39m\n\u001b[32m   1511\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1512\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1513\u001b[39m         \u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremote\u001b[49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1514\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1515\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (URLError, \u001b[38;5;167;01mTimeoutError\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/urllib/request.py:241\u001b[39m, in \u001b[36murlretrieve\u001b[39m\u001b[34m(url, filename, reporthook, data)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    225\u001b[39m \u001b[33;03mRetrieve a URL into a temporary location on disk.\u001b[39;00m\n\u001b[32m    226\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    237\u001b[39m \u001b[33;03mdata file as well as the resulting HTTPMessage object.\u001b[39;00m\n\u001b[32m    238\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    239\u001b[39m url_type, path = _splittype(url)\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m contextlib.closing(\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[32m    242\u001b[39m     headers = fp.info()\n\u001b[32m    244\u001b[39m     \u001b[38;5;66;03m# Just return the local path and the \"headers\" for file://\u001b[39;00m\n\u001b[32m    245\u001b[39m     \u001b[38;5;66;03m# URLs. No sense in performing a copy unless requested.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/urllib/request.py:216\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    215\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/urllib/request.py:525\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    524\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/urllib/request.py:634\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    631\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    632\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    633\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m634\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/urllib/request.py:563\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    561\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    562\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/urllib/request.py:496\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    495\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    498\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/urllib/request.py:643\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Model-model yang akan kita bandingkan\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Muat data\n",
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target\n",
    "\n",
    "# PENTING: Untuk cross-validation, kita bisa menggunakan seluruh dataset (X, y)\n",
    "# karena cross_val_score akan menangani pembagiannya secara internal.\n",
    "# Namun, untuk praktik terbaik, kita tetap akan memisahkan test set untuk evaluasi akhir di subchapter selanjutnya.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d502c953",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### 3. Langkah 1: Siapkan \"Kontestan\" (Daftar Model)\n",
    "\n",
    "Cara terbaik untuk mengelola beberapa model adalah dengan menyimpannya dalam sebuah *dictionary* atau *list*. Ini membuat proses evaluasi menjadi mudah untuk diotomatisasi dengan *loop*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f31f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "\t'Linear Regression': make_pipeline(\n",
    "\t\tStandardScaler(),\n",
    "\t\tLinearRegression()\n",
    "\t),\n",
    "\t'Ridge': make_pipeline(\n",
    "\t\tStandardScaler(),\n",
    "\t\tRidge()\n",
    "\t),\n",
    "\t'Lasso':make_pipeline(\n",
    "\t\tStandardScaler(),\n",
    "\t\tLasso()\n",
    "\t),\n",
    "\t'Decision Tree':make_pipeline(\n",
    "\t\tStandardScaler(),\n",
    "\t\tDecisionTreeRegressor()\n",
    "\t),\n",
    "\t'Random Forest':make_pipeline(\n",
    "\t\tStandardScaler(),\n",
    "\t\tRandomForestRegressor()\n",
    "\t),\n",
    "\t'Gradient Boosting':make_pipeline(\n",
    "\t\tStandardScaler(),\n",
    "\t\tGradientBoostingRegressor()\n",
    "\t),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b20402",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### 4. Langkah 2: Gelar \"Pertandingan\" (Loop dan Evaluasi)\n",
    "\n",
    "Sekarang kita akan membuat *loop* yang akan menjalankan 5-fold cross-validation pada setiap model di dalam *dictionary* `models`. Kita akan menghitung skor R² dan menyimpan hasilnya.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4bc9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai evaluasi model...\n",
      "Evaluasi untuk Linear Regression selesai.\n",
      "Evaluasi untuk Ridge selesai.\n",
      "Evaluasi untuk Lasso selesai.\n",
      "Evaluasi untuk Decision Tree selesai.\n",
      "Evaluasi untuk Random Forest selesai.\n",
      "Evaluasi untuk Gradient Boosting selesai.\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "print(\"Memulai evaluasi model...\")\n",
    "\n",
    "for name, model in models.items():\n",
    "\t# folding 5 cross validation\n",
    "\tscores = cross_val_score(model,X_train,y_train, cv=5, scoring='r2',n_jobs=-1)\n",
    "\n",
    "\t# simpan hasil\n",
    "\tresults[name] = {\n",
    "\t\t'mean_r2':np.mean(scores),\n",
    "\t\t'std_r2':np.std(scores)\n",
    "\t}\n",
    "\tprint(f\"Evaluasi untuk {name} selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34893d02",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### 5. Langkah 3: Umumkan \"Pemenang\" (Analisis Hasil)\n",
    "\n",
    "Setelah *loop* selesai, kita bisa mengubah hasilnya menjadi DataFrame Pandas untuk analisis yang mudah.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d0cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- Hasil Perbandingan Model ----\n",
      "                    mean_r2    std_r2\n",
      "Random Forest      0.804089  0.006002\n",
      "Gradient Boosting  0.786588  0.003194\n",
      "Linear Regression  0.611484  0.006467\n",
      "Ridge              0.611484  0.006460\n",
      "Decision Tree      0.607226  0.019406\n",
      "Lasso             -0.000317  0.000428\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "\n",
    "results_df = results_df.sort_values(by='mean_r2', ascending=False)\n",
    "\n",
    "print(\"\\n---- Hasil Perbandingan Model ----\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecf21d8",
   "metadata": {},
   "source": [
    "\n",
    "**Analisis Hasil:**\n",
    "\n",
    "Dari tabel di atas, kita dapat melihat peringkat performa model-model kita berdasarkan skor R² rata-rata dari 5-fold cross-validation:\n",
    "\n",
    "1.  **Gradient Boosting** dan **Random Forest** jelas merupakan dua model teratas, dengan performa yang sangat mirip dan kuat (R² mendekati 0.8).\n",
    "2.  **Ridge** dan **Linear Regression** berada di tingkat berikutnya, menunjukkan performa yang layak tetapi sedikit di bawah model-model ensemble.\n",
    "3.  **Lasso** memiliki performa yang sedikit lebih buruk, kemungkinan karena ia menolkan terlalu banyak koefisien.\n",
    "4.  **Decision Tree** tunggal, seperti yang kita duga, memiliki performa yang paling rendah di antara model-model non-linear karena kecenderungannya untuk *overfitting*.\n",
    "\n",
    "Perhatikan juga kolom `std_r2`. Model dengan `std_r2` yang lebih rendah lebih **stabil** atau konsisten performanya di berbagai subset data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7958dd4",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "### 6. Kesimpulan Tutorial\n",
    "\n",
    "Dengan beberapa baris kode dan sebuah *loop*, kita telah berhasil mengevaluasi 6 model berbeda secara adil dan sistematis. Kita sekarang memiliki bukti kuat bahwa **Gradient Boosting** dan **Random Forest** adalah kandidat terkuat kita.\n",
    "\n",
    "Di subchapter selanjutnya, kita akan belajar cara **memvisualisasikan** hasil ini menggunakan *box plot* untuk mendapatkan pemahaman yang lebih intuitif tentang performa dan stabilitas setiap model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
